<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Debugging natively compiled Java code with NativeJDB</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/nativejdb-debugger-for-native-images/&#xA;            " /><author><name>Mandana Vaziri (https://twitter.com/mandana_vaziri)</name></author><id>https://quarkus.io/blog/nativejdb-debugger-for-native-images/</id><updated>2022-06-29T00:00:00Z</updated><published>2022-06-29T00:00:00Z</published><summary type="html">Co-authored by: Ansu Varghese, Research Software Engineer, IBM In collaboration with: Max Andersen, Dimitris Andreadis, Andrew Dinn, Stuart Douglas, Jason Greene, David Grove, David Lloyd, Thomas Qvarnstrom, Foivos Zakkak, Galder Zamarreno (IBM Research and Red Hat) Quarkus is a cloud-native Java development framework, which allows Java code to be mapped...</summary><dc:creator>Mandana Vaziri (https://twitter.com/mandana_vaziri)</dc:creator><dc:date>2022-06-29T00:00:00Z</dc:date></entry><entry><title type="html">Kogito 1.23.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/06/kogito-1-23-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/06/kogito-1-23-0-released.html</id><updated>2022-06-28T08:38:11Z</updated><content type="html">We are glad to announce that the Kogito 1.23.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * Added endpoint to get source file content from a specific workflow * Added the get workflow source to the data index gateway API. * Token propagation support for OpenAPI extension * Runtime persistence now allows using Java serialization instead of protobuf definitions * gRPC operation type to Serverless functions BREAKING CHANGES * Source files add-on rest endpoint URL have been changed from ‘/management/process/{Id}/sources’ to ‘/management/processes/{processId}/sources’ to be aligned with the other management rest endpoints. * Removed deprecated add-ons, for a mapping of new artifact id visit . For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.20.0 artifacts are available at the . A detailed changelog for 1.23.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title>Cross-site scripting: Explanation and prevention with Go</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/28/cross-site-scripting-explanation-and-prevention-go" /><author><name>Sandipan Roy</name></author><id>ce361d82-7976-4221-8939-abdc16e1a282</id><updated>2022-06-28T07:00:00Z</updated><published>2022-06-28T07:00:00Z</published><summary type="html">&lt;p&gt;Have you ever encountered a pop-up when visiting a web page or browsing a particular item on a site? Imagine if these pop-ups were carriers that delivered malicious payloads to your devices or captured confidential information. This is a type of cyber attack called &lt;em&gt;cross-site scripting,&lt;/em&gt; or XSS. Cross-site scripting is one of the most common attacks in 2022, and it made the &lt;a href="https://owasp.org/www-project-top-ten/"&gt;OWASP top 10&lt;/a&gt; web application security risks. Let's take a tour of cross-site scripting and learn how an attacker executes malicious JavaScript code on input parameters, creates pop-ups to deface web applications, and can hijack an active user session.&lt;/p&gt; &lt;h3&gt;How JavaScript is used in XSS attacks&lt;/h3&gt; &lt;p&gt;A dynamic web application is set up with three key features:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;HTML specifies the complete structure.&lt;/li&gt; &lt;li&gt;CSS configures the overall look and feel.&lt;/li&gt; &lt;li&gt;JavaScript adds powerful interactions to the application, such as warning popups, rollover effects, drop-down menus, and more.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;JavaScript is the most popular scripting language. 95% of all websites are built and run via JavaScript. It implements interesting and powerful interactive features, and acts according to the user's actions.&lt;/p&gt; &lt;p&gt;Actions associated with executing JavaScript code include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;onclick&lt;/code&gt;: Executes JavaScript when the user clicks on a box or link.&lt;/li&gt; &lt;li&gt;&lt;code&gt;onload&lt;/code&gt;: Executes JavaScript after a web page or image is completely loaded. An example: &lt;pre&gt; &lt;code&gt;&lt;body onload=alert('Welcome to Red Hat')&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;&lt;code&gt;onmouseover&lt;/code&gt;: Triggers JavaScript when the mouse passes over a URL link. An example: &lt;pre&gt; &lt;code&gt;&lt;a onmouseover=alert("redhat.com")&gt;Contribute&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;&lt;code&gt;onmouseout&lt;/code&gt;: Triggers JavaScript if the mouse moves out of the window without clicking a URL.&lt;/li&gt; &lt;li&gt;&lt;code&gt;onunload&lt;/code&gt;: Triggers JavaScript when the user leaves the web page by closing the browser or clicking a link.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;XSS is a client-side code injection attack. In this kind of attack, websites are injected with malicious JavaScript code. XSS occurs when input parameters have not been correctly handled or validated in web applications, which allows an attacker to send malicious JavaScript code to a different end user. The end user's browser does not recognize it as a malicious script and falls into the XSS trap. This type of attack does not threaten users directly with a payload, but the attacker targets the XSS vulnerability by injecting a malicious script on a web page that seems to be a real part of the website. Thus, when any user visits this website, the XSS-afflicted website sends malicious JavaScript code to the user's browser without their knowledge.&lt;/p&gt; &lt;h2&gt;Types of XSS attacks&lt;/h2&gt; &lt;p&gt;There are a variety of types of XSS attacks, divided into three major categories:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Stored XSS,&lt;/strong&gt; also known as &lt;em&gt;permanent&lt;/em&gt; or type I XSS. In stored attacks, target servers store the injected script forever. The scripts maybe be stored in a database, on servers, or in forum comments. The victim unwittingly downloads that stored script from the server when attempting to access these resources.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Reflected XSS,&lt;/strong&gt; also known as type-II or &lt;em&gt;non-persistent XSS.&lt;/em&gt; These attacks happen when a web application instantly acknowledges the user's input without inspecting what has been entered. The attacker sends a malicious link via phishing to trick the user, and not store it on the webserver. There are two major types of reflected XSS: reflected XSS GET and reflected XSS POST.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;DOM-based XSS:&lt;/strong&gt; DOM-based XSS is a well-known vulnerability that happens in a document object model (DOM). The DOM defines web page segments such as the title, heading, table, forms, or a well-structured HTML page. If HTML documents are loaded into a web browser, they are transformed into a document object.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;3 defense strategies for XSS attacks&lt;/h2&gt; &lt;p&gt;Preventing cross-site scripting (XSS) attacks can be complicated, but these basic defense strategies are effective.&lt;/p&gt; &lt;h3&gt;Have a content security policy&lt;/h3&gt; &lt;p&gt;A content security policy (CSP) is a browser feature that allows you to create source lists for client-side web application resources, including JavaScript, CSS, and images. The CSP directs the browser to execute or display resources from specific sources using a special HTTP header.&lt;/p&gt; &lt;p&gt;In this example, the server only allows access to documents that are loaded over HTTPS via the single origin developers.redhat.com:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; Content-Security-Policy: default-src https://developers.redhat.com &lt;/code&gt; &lt;/pre&gt; &lt;h3&gt;Deploy the X-XSS-Protection header&lt;/h3&gt; &lt;p&gt;The XSS filter in recent web browsers is enabled by the X-XSS-Protection HTTP response header. Because the header is normally enabled by default, its function is to re-enable the filter for a specific website if the user has disabled it.&lt;/p&gt; &lt;h3&gt;Make use of modern development frameworks&lt;/h3&gt; &lt;p&gt;Modern JavaScript frameworks like AngularJS and ReactJS, along with server-side templating systems like Go Templates, offer good protection against reflected cross-site scripting.&lt;/p&gt; &lt;h2&gt;Vulnerable code examples&lt;/h2&gt; &lt;p&gt;In the previous sections, we examined JavaScript and its vulnerabilities. But a secure backend system like Go's &lt;a href="https://pkg.go.dev/net/http"&gt;HTTP Package&lt;/a&gt; can block misleading JavaScript functionality. Let's use this package to illustrate some analytic techniques.&lt;/p&gt; &lt;p&gt;In our first example, the &lt;code&gt;server()&lt;/code&gt; method reads the parameter &lt;code&gt;XYZ&lt;/code&gt; from the query string and returns it in the HTTP response. This method also handles HTTP GET requests. The &lt;a href="https://golang.org/pkg/net/http/#DetectContentType"&gt;http.DetectContentType&lt;/a&gt; function determines the default &lt;code&gt;content-type&lt;/code&gt; response header.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; package main import "io" import "net/http" func server(w http.ResponseWriter, r *http.Request) { io.WriteString(w, r.URL.Query().Get("XYZ")) } func main() { http.HandleFunc("/", server) http.ListenAndServe(":5000", nil) } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;content-type&lt;/code&gt; is set to &lt;code&gt;text/plain&lt;/code&gt; when delivering a payload with &lt;code&gt;XYZ=OpenSource&lt;/code&gt;, as you can see using a browser's developer tool (see Figure 1). This is not dangerous and is presented by the browser as plain text.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/crossScript-image1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/crossScript-image1.png?itok=ynwMjnaN" width="600" height="389" alt="Firefox developer tool" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: Firefox developer tool shows the network header request. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Firefox's developer tool shows the network header request.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;When I submit a request using &lt;code&gt;XYZ=&lt;script&gt;alert("RedHat")&lt;/script&gt;&lt;/code&gt;, the response's &lt;code&gt;Content-Type&lt;/code&gt; is set to &lt;code&gt;text/html&lt;/code&gt;, exposing the user to a cross-site scripting attack (see Figure 2).&lt;/p&gt; &lt;figure role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/crossScript-img2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/crossScript-img2.png?itok=HUx0HLQg" width="600" height="386" alt="Firefox developer tool" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Executing our malicious JavaScript code processed by the backend. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;This JavaScript delivery can do harmful things, and we must fix it. Fortunately, changing a simple package in Go can prevent it.&lt;/p&gt; &lt;p&gt;The example vulnerability can be minimized by encoding the user-controlled parameter's output. Several output encoding routines are included in the &lt;code&gt;html/template package&lt;/code&gt; in Go. The problem in this example can be solved by using the &lt;code&gt;HTMLEscapeString&lt;/code&gt; method to perform output encoding on the user-supplied input:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; import "io" import "net/http" func server(w http.ResponseWriter, r * http.Request) { encodedParam = template.HTMLEscapeString(r.URL.Query().Get("XYZ")) io.WriteString(w, encodedParam) } func main() { http.HandleFunc("/", server) http.ListenAndServe(":8080", nil) } &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Now let's consider a second example. The &lt;code&gt;server()&lt;/code&gt; function reads the parameter error from the query string and adds it to the template (&lt;code&gt;text/template module&lt;/code&gt;) that handles HTTP GET requests. The &lt;a href="https://golang.org/pkg/net/http/#DetectContentType"&gt;http.DetectContentType&lt;/a&gt; function determines the default &lt;code&gt;content-type&lt;/code&gt; response header.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; import "net/http" import "text/template" func server(w http.ResponseWriter, r *http.Request) { error := r.URL.Query().Get("XYZ") tmpl := template.New("ERROR") tmpl, _ = tmpl.Parse(`{{define "T"}}{{.}}{{end}}`) tmpl.ExecuteTemplate(w, "T", error) } func main() { http.HandleFunc("/", server) http.ListenAndServe(":5000", nil) } &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;When I submit a request using &lt;code&gt;XYZ=&lt;script&gt;alert("RedHat")&lt;/script&gt;&lt;/code&gt;, the response's &lt;code&gt;content-type&lt;/code&gt; sets to &lt;code&gt;text/html&lt;/code&gt;, exposing the user to cross-site scripting, as shown in Figure 3.&lt;/p&gt; &lt;figure role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/crossScript-img3.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/crossScript-img3.png?itok=TfJK8Qa5" width="600" height="385" alt="Firefox developer tool" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: Executing the malicious JavaScript code and successfully injecting our code. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;To fix this vulnerable code, replace the &lt;code&gt;text/template&lt;/code&gt; import with &lt;code&gt;html/template&lt;/code&gt; with built-in output encoding capabilities:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; import "net/http" import "html/template" func server(w http.ResponseWriter, r *http.Request) { error: = r.URL.Query().Get("XYZ") tmpl: = template.New("ERROR") tmpl, _ = tmpl.Parse(`{{define "T"}}{{.}}{{end}}`) tmpl.ExecuteTemplate(w, "T", error) } func main() { http.HandleFunc("/", server) http.ListenAndServe(":5000", nil) }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When a request with &lt;code&gt;XYZ=&lt;script&gt;alert("RedHat")&lt;/script&gt;&lt;/code&gt; is sent, the updated code successfully encodes the payload (see Figure 4). The fixed backend code has successfully filtered the attack, preventing it from executing malicious JavaScript code.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/crossScript-img4.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/crossScript-img4.png?itok=fWEdg0EM" width="600" height="386" alt="Firefox developer tool" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Executing malicious JavaScript code but backend blocked the request. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: The backend blocks a request for malicious JavaScript code.&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Cutting-edge programming languages like Go make it easy to fix security issues such as cross-site scripting, server-side request forgery, and comment injections. With secure coding practices and continuous security testing, you can prevent various cyber-attacks. Learn more about secure coding practice by reviewing the &lt;a href="https://github.com/OWASP/Go-SCP"&gt;OWASP secure coding practice guide&lt;/a&gt;, or read &lt;a href="https://nostarch.com/blackhatgo"&gt;Black Hat Go&lt;/a&gt; for information about security penetration testing.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/28/cross-site-scripting-explanation-and-prevention-go" title="Cross-site scripting: Explanation and prevention with Go"&gt;Cross-site scripting: Explanation and prevention with Go&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Sandipan Roy</dc:creator><dc:date>2022-06-28T07:00:00Z</dc:date></entry><entry><title type="html">How to build GraphQL applications with Quarkus</title><link rel="alternate" href="http://www.mastertheboss.com/soa-cloud/quarkus/how-to-build-graphql-applications-with-quarkus/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/soa-cloud/quarkus/how-to-build-graphql-applications-with-quarkus/</id><updated>2022-06-27T07:13:00Z</updated><content type="html">GraphQL is an open-source query and data manipulation language for APIs. This article shows how to create and deploy a sample application using a Quarkus Runtime What is GraphQL? GraphQL is Query language for reading and mutating data in APIs. As a back-end developer, GraphQL provides a type system where you can describe a schema ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Use a SystemTap example script to trace kernel code operation</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/27/use-systemtap-example-script-trace-kernel-code-operation" /><author><name>William Cohen</name></author><id>4fb43103-07ae-4807-898e-53be38312be1</id><updated>2022-06-27T07:00:00Z</updated><published>2022-06-27T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://sourceware.org/systemtap/"&gt;SystemTap&lt;/a&gt; allows developers to add instrumentation to &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; systems to better understand the behavior of the kernel as well as userspace applications and libraries. This article, the first in a two-part series, shows how SystemTap can reveal potential performance problems down to individual lines of code. The second part of the series will describe how a SystemTap performance monitoring script was written.&lt;/p&gt; &lt;h2&gt;The SystemTap examples repository&lt;/h2&gt; &lt;p&gt;Writing a program from scratch in an unfamiliar language can be daunting. To make it easier for people to use SystemTap, the project provides a &lt;a href="https://sourceware.org/git/?p=systemtap.git;a=tree;f=testsuite/systemtap.examples"&gt;collection of examples&lt;/a&gt;. Some investigate common system issues. Other examples are there to demonstrate particular SystemTap features.&lt;/p&gt; &lt;p&gt;To provide a bit of structure and make it easier to locate desired scripts out of the approximately 200 SystemTap examples, they are divided into subdirectories. Additionally, each of the examples has associated keywords such as "NETWORK", "DISK", "NFS", and "PROCESS." These keywords are used to create &lt;a href="https://sourceware.org/systemtap/examples/keyword-index.html"&gt;indexes&lt;/a&gt; that make it easier to find a script that implements the instrumentation you are interested in or provides a good starting point for your particular needs.&lt;/p&gt; &lt;p&gt;For example, suppose you want to better understand a section of code and where it is taking a lot of execution time. Other tools on Linux, such as &lt;code&gt;perf&lt;/code&gt;, can identify the hot spots in the code, but you might like to have some additional information about the control flow in the program. You look at the examples associated with the PROFILING keyword and find a &lt;a href="https://sourceware.org/systemtap/examples/profiling/linetimes.stp"&gt;&lt;code&gt;linetimes.stp&lt;/code&gt; script&lt;/a&gt; that looks promising. This article shows how to use this script as an illustration of SystemTap's capabilities as well as preparation for the programming guidelines in the second part of the series.&lt;/p&gt; &lt;h2&gt;Profiling with linetime.stp&lt;/h2&gt; &lt;p&gt;SystemTap examples are installed as part of the systemtap-client RPM in the &lt;code&gt;/usr/share/systemtap/examples&lt;/code&gt; directory in &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; and &lt;a href="https://fedoraproject.org"&gt;Fedora&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;linetimes.stp&lt;/code&gt; script takes two arguments. The first argument determines whether the kernel, a kernel module, or a user-space binary is being monitored. The second argument is the name of the function being monitored.&lt;/p&gt; &lt;p&gt;To get a better understanding of the &lt;code&gt;nfsd4_open&lt;/code&gt; function in the kernel file &lt;code&gt;fs/nfsd/nfs4proc.c&lt;/code&gt;, I ran the following command on a Red Hat Enterprise Linux 8 machine running as an NFS server. The &lt;code&gt;--example&lt;/code&gt; option indicates that the script is in the examples directory. Because the NFS server code is compiled as the &lt;code&gt;nfsd&lt;/code&gt; module, the command needs to specify the code location with &lt;code&gt;module("nfsd")&lt;/code&gt;. Core kernel code would be specified as &lt;code&gt;kernel&lt;/code&gt;. The function name, &lt;code&gt;nfsd4_open&lt;/code&gt;, follows on the command line. The &lt;code&gt;-c "sleep 10"&lt;/code&gt; argument runs the script for 10 seconds and then exits:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ sudo stap --example linetimes.stp 'module("nfsd")' nfsd4_open -c "sleep 10"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I got the following output from the script. The opening line states that the function was called 12 times. Looking through the times listed for the regions, I see that one line, 418, stands out as being very expensive with an average runtime of 3,937 microseconds:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;module("nfsd") nfsd4_open call count: 12 region avg(us) max(us) module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:352") 2 4 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:353") 2 4 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:354") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:357") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:358") 6 8 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:365") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:368") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:373") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:374") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:378") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:382") 5 18 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:383") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:395") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:397") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:402") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:403") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:408") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:411") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:415") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:418") 3937 8962 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:419") 8 16 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:431") 5 5 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:432") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:453") 5 7 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:454") 2 3 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:457") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:460") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:461") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:462") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:463") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:465") 1 3 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:466") 1 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:467") 1 2&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The source file containing this line is:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;/usr/src/debug/kernel-4.18.0-375.el8/linux-4.18.0-375.el8.x86_64/fs/nfsd/nfs4proc.c&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;A few relevant lines from the source code follow:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;415 switch (open-&gt;op_claim_type) { 416 case NFS4_OPEN_CLAIM_DELEGATE_CUR: 417 case NFS4_OPEN_CLAIM_NULL: 418 status = do_open_lookup(rqstp, cstate, open, &amp;resfh); 419 if (status) 420 goto out; 421 break; 422 case NFS4_OPEN_CLAIM_PREVIOUS: 423 status = nfs4_check_open_reclaim(cstate-&gt;clp); 424 if (status) 425 goto out; 426 open-&gt;op_openowner-&gt;oo_flags |= NFS4_OO_CONFIRMED; 427 reclaim = true; 428 /* fall through */ 429 case NFS4_OPEN_CLAIM_FH: 430 case NFS4_OPEN_CLAIM_DELEG_CUR_FH: 431 status = do_open_fhandle(rqstp, cstate, open); 432 if (status) 433 goto out; 434 resfh = &amp;cstate-&gt;current_fh; 435 break;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;A look at the source file reveals that line 418 contains a &lt;code&gt;do_open_lookup&lt;/code&gt; function call. To find out why the call is happening so often, it would make sense to perform the steps shown in this section on that function, but we won't pursue the matter further in this article.&lt;/p&gt; &lt;p&gt;Following the timing information, the script outputs a control flow graph. Each line of output shows the module name followed by information about the executing statement: the function name followed by an ampersand, the filename followed by a colon, and the line number within the filename. A &lt;code&gt;from&lt;/code&gt; line is generated for each statement that runs, followed by a list of indented &lt;code&gt;to&lt;/code&gt; lines indicating the statements that followed at various times.&lt;/p&gt; &lt;p&gt;The following output shows that much of the control flow in the function is linear, because each &lt;code&gt;from&lt;/code&gt; line is followed by a single &lt;code&gt;to&lt;/code&gt; destination. A linear flow is also suggested when the number of times a line runs is 12, the same as the function itself. However, some &lt;code&gt;from&lt;/code&gt; statements are followed by more than one &lt;code&gt;to&lt;/code&gt; destination, indicating a branch:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;control flow graph information from to ======================= module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:352") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:353") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:353") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:354") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:354") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:357") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:357") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:358") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:358") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:365") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:365") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:368") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:368") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:373") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:373") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:374") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:374") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:378") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:378") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:382") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:382") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:383") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:383") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:395") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:395") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:397") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:397") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:402") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:402") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:403") 6 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:408") 6 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:403") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:408") 6 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:408") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:411") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:411") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:415") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:415") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:418") 8 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:431") 4 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:418") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:419") 6 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:461") 2 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:419") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:461") 6 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:431") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:432") 4 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:432") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:453") 4 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:453") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:454") 4 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:454") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:457") 4 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:457") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:460") 4 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:460") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:465") 4 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:461") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:462") 8 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:462") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:463") 8 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:463") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:465") 8 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:465") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:466") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:466") module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:467") 12 module("nfsd").statement("nfsd4_open@fs/nfsd/nfs4proc.c:467") module("nfsd").function("nfsd4_open@fs/nfsd/nfs4proc.c:350").return 12&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In particular, note the first &lt;code&gt;from&lt;/code&gt; line for &lt;code&gt;nfsd4_open@fs/nfsd/nfs4proc.c&lt;/code&gt;, line 415. This line is a switch statement that invokes &lt;code&gt;nfsd4_open@fs/nfsd/nfs4proc.c&lt;/code&gt;, line 418, 8 times, and invokes &lt;code&gt;nfsd4_open@fs/nfsd/nfs4proc.c&lt;/code&gt;, line 431, 4 times. Lines 418 and 431 are different case statements in the switch-case statement. This information can be used to better understand the paths through the code.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;SystemTap offers many example scripts out of the box to help uncover potential system problems. The example index helps you find appropriate scripts. These existing scripts can be easily run, as demonstrated in this article. The scripts can also be used as a starting point for your own instrumentation and a way to better understand how to write your own SystemTap scripts. The second article in the series will walk through the &lt;code&gt;linetimes.stp&lt;/code&gt; example to teach how you can create or adapt a SystemTap script to your needs.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/27/use-systemtap-example-script-trace-kernel-code-operation" title="Use a SystemTap example script to trace kernel code operation"&gt;Use a SystemTap example script to trace kernel code operation&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>William Cohen</dc:creator><dc:date>2022-06-27T07:00:00Z</dc:date></entry><entry><title>The road to JBoss EAP 8</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/24/road-jboss-eap-8" /><author><name>James Falkner</name></author><id>a3d6c262-c5b5-4a9d-a479-3e99000ee793</id><updated>2022-06-24T07:00:00Z</updated><published>2022-06-24T07:00:00Z</published><summary type="html">&lt;p&gt;As a leading, open source, &lt;a href="https://jakarta.ee/compatibility/"&gt;Jakarta Enterprise Edition (Jakarta EE)-compatible&lt;/a&gt; application server, &lt;a href="https://developers.redhat.com/products/eap/overview"&gt;Red Hat JBoss Enterprise Application Platform&lt;/a&gt; (JBoss EAP) has been a trusted workhorse for enterprise &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; workloads for the past decade. This article describes how the Jakarta EE specifications have evolved since the release of the current version, JBoss EAP 7, and what you can look forward to with JBoss EAP 8.&lt;/p&gt; &lt;p&gt;JBoss EAP 7 is optimized for cloud environments, and when deployed with &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;, offers &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt;, load balancing, elastic scaling, health monitoring, and the ability to deploy to a container directly from the IDE to improve developer productivity and experience.&lt;/p&gt; &lt;h2&gt;Jakarta EE evolution&lt;/h2&gt; &lt;p&gt;Red Hat is one of the founding members of the &lt;a href="https://jakarta.ee/"&gt;Jakarta EE&lt;/a&gt; working group and has been actively involved in innovating and contributing since the earliest days of Java Enterprise Edition (Java EE). After the move of Java EE from Oracle to Jakarta EE at the Eclipse Foundation, &lt;a href="https://jakarta.ee/news/jakarta-ee-8-released/"&gt;Jakarta EE 8 was released&lt;/a&gt; and set the specifications on a much more vendor-neutral footing, a shift championed by Red Hat and other vendors.&lt;/p&gt; &lt;p&gt;The next major release, &lt;a href="https://jakarta.ee/specifications/platform/9/"&gt;Jakarta EE 9&lt;/a&gt;, did not introduce significant new features but instead made the big move of changing the Jakarta API package namespace from &lt;code&gt;javax.*&lt;/code&gt; to &lt;code&gt;jakarta.*&lt;/code&gt;. The name change introduced a major incompatibility with existing programs. Jakarta EE 9 was largely seen as a stepping stone to the next major version, Jakarta EE 10. JBoss EAP does not support this stepping stone because, without compelling new reasons to switch, the adoption of Jakarta EE 9 would have caused unnecessary churn in our customer base and their applications, with no real added value to compensate.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://eclipse-ee4j.github.io/jakartaee-platform/jakartaee10/JakartaEE10#jakarta-ee-10-schedule"&gt;current plan for Jakarta EE 10&lt;/a&gt; calls for a release in Q2 2022 and presents an opportunity to create a significant revision to the platform compared to Jakarta EE 8 (identical to Java EE 8), and Jakarta EE 9 (with the namespace change).&lt;/p&gt; &lt;p&gt;Several specifications under Jakarta EE are getting new features. One of the more prominent is the introduction of a &lt;a href="https://projects.eclipse.org/projects/ee4j.jakartaee-platform/releases/core-profile-10"&gt;Core profile&lt;/a&gt; (complementing the existing Full and Web profiles that have been in Java EE or Jakarta EE for years). The new profile contains a subset of Jakarta EE specifications that are most useful for smaller, focused applications such as microservices, serverless workloads, and natively ahead-of-time compiled apps. The Core profile is a great step forward for the specification and moves Jakarta EE more into the cloud-native and container space.&lt;/p&gt; &lt;h2&gt;What's planned for JBoss EAP 8&lt;/h2&gt; &lt;p&gt;As always, customers should refer to the officially published &lt;a href="https://access.redhat.com/support/policy/updates/jboss_notes"&gt;life cycles of the Runtimes products&lt;/a&gt; (including EAP) to plan upgrades and migrations for their deployed Runtimes. The information in this article is subject to change without notice.&lt;/p&gt; &lt;p&gt;JBoss EAP is based on the upstream &lt;a href="http://wildfly.org"&gt;WildFly&lt;/a&gt; project. That project is &lt;a href="https://www.wildfly.org/news/2022/01/21/WildFly-2022/"&gt;moving to a feature-boxed release&lt;/a&gt; to align more closely with the way Jakarta EE evolves, and the first version of WildFly to support Jakarta EE 10 will be WildFly 27. So keep an eye on WildFly if you want to get a sneak peek of what's to come in JBoss EAP.&lt;/p&gt; &lt;p&gt;The next major EAP release, JBoss EAP 8, is slated for the first half of 2023, with a Beta release targeting the second half of 2022. The Beta release will give customers a chance to test drive the new features but, more importantly, to plan their migration from earlier versions of JBoss EAP. Along with new features will be an update to platform support for newer versions of &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt;, Red Hat OpenShift, Windows, databases, and other dependencies. The final list will be determined closer to release.&lt;/p&gt; &lt;p&gt;Support for the existing version, JBoss EAP 7.x, has been extended in order to provide additional time for current customers to plan their migration to JBoss EAP 8. Consult the &lt;a data-saferedirecturl="https://www.google.com/url?q=https://access.redhat.com/support/policy/updates/jboss_notes%23p_eap&amp;amp;source=gmail&amp;amp;ust=1655388538009000&amp;amp;usg=AOvVaw393mBgGjQ2XOIfUo9dz0ue" href="https://access.redhat.com/support/policy/updates/jboss_notes#p_eap" target="_blank"&gt;Product Support and Update Policy page&lt;/a&gt; for updated support dates for JBoss EAP. &lt;/p&gt; &lt;h2&gt;Product life cycle&lt;/h2&gt; &lt;p&gt;Similar to the current version of JBoss EAP, customers will continue to enjoy long-term support for JBoss EAP 8, corresponding to Red Hat Application Services' &lt;a href="https://access.redhat.com/support/policy/updates/jboss_notes#duration"&gt;Long-life Product Life Cycle&lt;/a&gt;. Coupled with industry-leading &lt;a href="https://www.redhat.com/en/services/support"&gt;24x7 support&lt;/a&gt; and multi-year update and maintenance policies, this commitment gives customers peace of mind that Red Hat can support their most important applications for years to come.&lt;/p&gt; &lt;h2&gt;Migrating to JBoss EAP 8&lt;/h2&gt; &lt;p&gt;EAP 7 continues to be supported based on its &lt;a href="https://access.redhat.com/support/policy/updates/jboss_notes#p_eap"&gt;support life cycle&lt;/a&gt;. Customers should begin planning for migration to EAP 8 to continue to enjoy support beyond the EAP 7 life cycle. As we get closer to EAP 8 Beta later this year, more migration details will be available. But generally, migrations consist of two main areas:  servers and applications.&lt;/p&gt; &lt;h3&gt;Server migration&lt;/h3&gt; &lt;p&gt;This process includes the migration of JBoss EAP configuration files such as &lt;code&gt;standalone.xml&lt;/code&gt;. The &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.4/html-single/migration_guide/index#migration_tool_server_migration_tool"&gt;JBoss Server Migration Tool&lt;/a&gt; is the preferred method to update your server configuration to include the new features and settings in new JBoss EAP releases while keeping your existing configuration. The JBoss Server Migration Tool reads your existing JBoss EAP server configuration files and adds configurations for any new subsystems, updates the existing subsystem configurations with new features, and removes any obsolete or "pruned" subsystem configurations.&lt;/p&gt; &lt;p&gt;A preview of this tool will be included as part of the JBoss EAP 8 Beta release. To understand how it works in detail, consult the existing EAP 7 documentation on this migration tool (which will be updated for EAP 8).&lt;/p&gt; &lt;h3&gt;Application migration&lt;/h3&gt; &lt;p&gt;The main migration topic here is the change of Jakarta API namespaces from &lt;code&gt;javax.*&lt;/code&gt; to &lt;code&gt;jakarta.*&lt;/code&gt;. In many cases, this change requires just a simple substitution (and the migration toolkit has new support for things such as &lt;a href="https://docs.openrewrite.org/"&gt;OpenRewrite&lt;/a&gt; recipes to automate this), but not in all cases.&lt;/p&gt; &lt;p&gt;To assist in migrating applications, customers can use the &lt;a href="https://developers.redhat.com/products/mta/overview"&gt;migration toolkit for applications&lt;/a&gt;. This toolkit is an extensible and customizable rule-based set of tools that helps simplify the migration of Java applications. It analyzes the APIs, technologies, and architectures used by the applications you plan to migrate and provides detailed migration reports for each application. This tool will support migrations to JBoss EAP 8 Beta (for testing purposes only) and JBoss EAP 8 GA once it is released. More details on exactly how to migrate to EAP 8 will be available closer to the EAP 8 Beta release.&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.redhat.com/en/topics/application-modernization"&gt;Application migration and modernization&lt;/a&gt; is a large topic by itself. Red Hat continues to innovate here as well, with new projects such as &lt;a href="https://www.redhat.com/architect/tackle-application-modernization"&gt;Tackle&lt;/a&gt; (part of the &lt;a href="https://www.konveyor.io/"&gt;Konveyor&lt;/a&gt; community), which eases the migration and modernization of applications as they transition to the cloud, containers, and Kubernetes.&lt;/p&gt; &lt;p&gt;Keep watching this publication site, as well as the official new &lt;a href="https://twitter.com/redhatjava"&gt;@RedHatJava Twitter stream&lt;/a&gt;, for more details as we approach the release of JBoss EAP 8.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/24/road-jboss-eap-8" title="The road to JBoss EAP 8"&gt;The road to JBoss EAP 8&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>James Falkner</dc:creator><dc:date>2022-06-24T07:00:00Z</dc:date></entry><entry><title type="html">Keycloak 18.0.2 released</title><link rel="alternate" href="https://www.keycloak.org/2022/06/keycloak-1802-released" /><author><name /></author><id>https://www.keycloak.org/2022/06/keycloak-1802-released</id><updated>2022-06-24T00:00:00Z</updated><content type="html">To download the release go to . MIGRATION FROM 17.0 Before you upgrade remember to backup your database. If you are not on the previous release refer to for a complete list of migration changes. ALL RESOLVED ISSUES BUGS * New admin console inaccessible keycloak admin/ui UPGRADING Before you upgrade remember to backup your database and check the for anything that may have changed.</content><dc:creator /></entry><entry><title type="html">Profiling to improve DMN file&amp;#8217;s loading time</title><link rel="alternate" href="https://blog.kie.org/2022/06/profiling-to-improve-dmn-files-loading-time.html" /><author><name>Daniel José dos Santos</name></author><id>https://blog.kie.org/2022/06/profiling-to-improve-dmn-files-loading-time.html</id><updated>2022-06-23T19:45:54Z</updated><content type="html">One of my passions is to run profiling tools to find places in the code where performance improvements can be made. Sometimes, we are strongly convinced to know where bottlenecks are, and then, after running a profiler, find out that something completely different is making everything slow. This is one of those cases. In this article, I’ll show you how to profile a GWT application, the DMN Editor. WHAT IS PROFILING? In a nutshell: it is to run a tool against your running application that takes “snapshots” of what is being processed in terms of CPU, memory, I/O, and so on and at the end compare all the “snapshots” to see what it is being shown most of the time in those “snapshots”. FREE PRO-TIP RUNNING ANY PROFILING TOOL Sometimes the entire process that you want to analyze takes too much time, like minutes or even hours. You don’t need to run the profile for all that time otherwise you’ll produce an amount of data so big that analyzing that will be another problem. Of course, if the process takes, for example, 3 minutes but the first minute is slow because of one cause and the remaining minutes are slow because of another thing, a good strategy is to run the profile more times choosing the specific frame time that you want to analyze. WHAT TOOL DO I USE? For this scenario, which is to profile a GWT application, I use the Firefox Profiling Tool available in the Firefox Developer edition. Keep in mind that the tool choice depends on your programming language, where are you running your application (desktop, web), and so on THE REAL CASE In this scenario, we have a very large DMN model that was taking almost 4 minutes to load. And after being loaded, it still doesn’t seem that it was loaded like there is something that is still running in the background causing browser slowness and sometimes making it crash. To start I decided to analyze only the first 30 seconds to see if I got any clue there. RUNNING THE PROFILING TOOL All set, it’s time to run the DMN Editor for the first time! In the Firefox Developer, I hit F12 to show the developer tools. Then I go to the “Performance” tab. Finally, I started the loading of the DMN model which was taking too much time to load. I clicked on “Start recording” and waited a few seconds…. Clicked on “Capture record”. Firefox then loaded my data to profiler.firefox.com, and show me the results with the hot path expanded: Everything is clear now! The method _Kv_g being called by JcG_g called by sjm_g was my bottleneck! Wait… wait… what??? PROFILING GWT A part of our code is written in GWT. For those not aware: the code is written in Java and then “transpiled” to JavaScript. In other words, the code written in Java is “translated” to pure JavaScript code. But obfuscated (not readable by human beings). To debug we use a source map which is handled by the browser. Source map, as its names suggest, it is a “map” that tells the debugger what/where is the real code of the running code. So the method _Kv_g that we saw before is shown in the debugger like executeMyHappyMethod(). Or something like that. But unfortunately, it seems it doesn’t work for profiling. All we saw is the obfuscated code. But don’t panic. You just need to rebuild your application by changing the GWT transpiler from its default “generate obfuscated code” to “generate pretty code”. There are many ways to do that, it depends on the structure of your project but at the end of the day you just need to pass the parameter “-style PRETTY” to the GWT transpiler. In the case of our project, I had to change the pom.xml files to something like that: &lt;plugin&gt;   &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;   &lt;artifactId&gt;gwt-maven-plugin&lt;/artifactId&gt;   &lt;configuration&gt;   &lt;style&gt;PRETTY&lt;/style&gt; (…) the rest of the settings Now everything is ready for a proper profiling phase. In the next post of this series, I finally show how we reduced the loading time of a file from around 3:53 minutes to 33 seconds with a simple change! Stay tuned! The post appeared first on .</content><dc:creator>Daniel José dos Santos</dc:creator></entry><entry><title>Multi-cloud storage strategies for SaaS applications</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/23/multi-cloud-storage-strategies-saas-applications" /><author><name>Michael Hrivnak</name></author><id>954895a5-82f1-45f3-8b0f-fedb7d86c6a4</id><updated>2022-06-23T07:00:00Z</updated><published>2022-06-23T07:00:00Z</published><summary type="html">&lt;p&gt;The &lt;a href="https://developers.redhat.com/articles/2022/05/18/saas-architecture-checklist-kubernetes"&gt;SaaS architecture checklist&lt;/a&gt; is a series of articles that cover the software and deployment considerations for &lt;a href="https://www.redhat.com/en/topics/cloud-computing/what-is-saas"&gt;Software as a Service (SaaS)&lt;/a&gt; applications. In this fourth article in the series, you'll learn about software SaaS providers can use to simplify their storage architecture while still accommodating a multi-cloud strategy.&lt;/p&gt; &lt;h2&gt;Bring your service to your customer's platforms&lt;/h2&gt; &lt;p&gt;A multi-cloud strategy is critical if you want to enable your SaaS application to run in the same physical location that your end customers use. Running on the same network is essential when a SaaS processes a large amount of end customer data or integrates closely with end customer systems. This keeps latency low and avoids expensive charges for inter-region or inter-cloud bandwidth. Since it is unlikely that a SaaS provider’s entire target market uses the same cloud provider, they must operate their service on multiple cloud platforms. In other words, you must bring your service to your customers.&lt;/p&gt; &lt;p&gt;The first step is to choose a portable Kubernetes distribution, such as &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;, to normalize the operational burden across clouds. Your goal should be to avoid having to do unique development, configuration, lifecycle management, change management, and API integration for each deployment platform (see Figure 1). But certain capabilities remain cloud-specific, and &lt;a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/"&gt;persistent storage&lt;/a&gt; is one that almost every SaaS provider needs to use. If your SaaS application stores persistent data, you can still be left dealing with feature differences among the storage offerings of various clouds, such as dynamic provisioning, shared access, snapshots, security controls, and which of the three types of storage—block, filesystem, or object—are offered. Accommodating those differences can lead to costly efforts by development, operations, and support teams.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Multi-cloud%20storage-image1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Multi-cloud%20storage-image1.png?itok=rJQtPUV9" width="600" height="599" alt="Red Hat OpenShift infrastructure experience" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: Red Hat OpenShift provides a consistent infrastructure experience across cloud environments. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;&lt;a href="https://www.redhat.com/en/topics/data-storage/software-defined-storage"&gt;Software-defined storage&lt;/a&gt; (SDS) is a common architectural pattern that provides a consistent feature set across public and private cloud environments. SDS is sometimes referred to as &lt;em&gt;hyperconverged infrastructure&lt;/em&gt; (HCI), where raw storage devices, compute resources, software-defined storage solutions, and workloads are all part of the same Kubernetes cluster. One SDS system can run in many cloud environments as long as block devices are available to individual hosts within the cluster.&lt;/p&gt; &lt;p&gt;Software-defined storage decouples hardware storage devices from the logical storage mechanisms accessed by software. For example, three servers could have one or more physical storage devices available to the SDS system. The SDS system would be installed across the three servers and configured to use the physical devices as one pool (see Figure 2). With a pool of raw storage, you can configure the system to aggregate and expose the raw storage as a logical block, filesystem, or object storage over the network. You can also configure the system for redundancy, maintaining a set number of copies of data across multiple underlying hosts.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/software-defined-storage_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/software-defined-storage_0.png?itok=r90t4g4-" width="600" height="450" alt="software-defined storage diagram" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: A software-defined storage system utilizes raw storage devices from multiple nodes in an OpenShift cluster, presenting them as a highly-available pool of storage. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;h2&gt;A team of software solutions&lt;/h2&gt; &lt;p&gt;These three technologies can be combined to form a complete software-defined storage solution:&lt;/p&gt; &lt;h3&gt;Ceph&lt;/h3&gt; &lt;p&gt;&lt;a href="https://ceph.com/"&gt;Ceph&lt;/a&gt; is a popular open source software-defined storage platform (and number one for OpenStack) that can turn commodity block devices across multiple hosts into a high-performance, fault-tolerant storage cluster. It exposes object, filesystem, and block storage used by applications running in Kubernetes. Ceph has excellent management capabilities, including snapshots, cloning, and automated rebalancing and recovery. Ceph has become a popular choice for software-defined storage due to its rich feature set enabling a variety of storage use cases and the flexibility to run almost anywhere.&lt;/p&gt; &lt;h3&gt;Rook&lt;/h3&gt; &lt;p&gt;&lt;a href="https://rook.io/"&gt;Rook&lt;/a&gt; is a &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Kubernetes Operator&lt;/a&gt; that offers a Kubernetes-native method for deploying and managing Ceph. According to Rook's website, it "turns distributed storage systems into self-managing, self-scaling, self-healing storage services. It automates the tasks of a storage administrator: deployment, bootstrapping, configuration, provisioning, scaling, upgrading, migration, disaster recovery, monitoring, and resource management." Rook has become a leading option because it offers enterprise-grade storage within a Kubernetes cluster through the HCI approach.&lt;/p&gt; &lt;h3&gt;Noobaa&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.noobaa.io/"&gt;Noobaa&lt;/a&gt; adds advanced object storage capabilities, including deduplication, compression, and encryption at rest. Mirroring and replication policies distribute data across multiple backing storage services, even in different cloud environments.&lt;/p&gt; &lt;p&gt;Bringing these capabilities into an OpenShift cluster is easy with &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift-data-foundation"&gt;Red Hat OpenShift Data Foundation&lt;/a&gt;, because it combines Ceph, Rook, and Noobaa as one optional operator. Following the HCI pattern with OpenShift and OpenShift Data Foundation enables you to operate your SaaS application across multiple public and private clouds with just one storage platform and one Kubernetes platform. Operations teams prefer having only one software lifecycle to track, a consistent set of APIs and capabilities, a limited surface area of domain expertise to maintain, and a single point of support. Development teams save time by focusing on one storage and compute platform for testing and validation.&lt;/p&gt; &lt;h2&gt;Learn more about Kubernetes storage&lt;/h2&gt; &lt;p&gt;To learn more about Kubernetes storage solutions, a great resource is &lt;a href="https://www.redhat.com/en/engage/kubernetes-containers-storage-s-201911201051"&gt;Storage Patterns for Kubernetes For Dummies, Red Hat Special Edition&lt;/a&gt;. Chapter two covers specific details about this topic. For further explanation of storage primitives and concepts on OpenShift, refer to the &lt;a href="https://docs.openshift.com/container-platform/4.10/storage/index.html"&gt;OpenShift Container Platform Storage Overview&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/23/multi-cloud-storage-strategies-saas-applications" title="Multi-cloud storage strategies for SaaS applications"&gt;Multi-cloud storage strategies for SaaS applications&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Michael Hrivnak</dc:creator><dc:date>2022-06-23T07:00:00Z</dc:date></entry><entry><title>Measuring BPF performance: Tips, tricks, and best practices</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/22/measuring-bpf-performance-tips-tricks-and-best-practices" /><author><name>Dmitrii Dolgov, Giles Hutton</name></author><id>ac707552-31bd-4ac8-8dc0-505801fafd8b</id><updated>2022-06-22T07:00:00Z</updated><published>2022-06-22T07:00:00Z</published><summary type="html">&lt;p&gt;Measuring stuff is harder than you may think. Even in math, there is such a thing as non-measurable sets and &lt;a href="https://en.wikipedia.org/wiki/Banach%E2%80%93Tarski_paradox"&gt;Banach-Tarski paradox&lt;/a&gt;, which shows that a three-dimensional ball of radius 1 can be dissected into 5 parts, which can be magically reassembled to form two balls of radius 1. Now imagine what kind of mess we've got in software engineering.&lt;/p&gt; &lt;p&gt;This may sound somewhat philosophical, so let's get down to earth and talk about BPF programs. BPF, which originally stood for &lt;em&gt;Berkeley Packet Filter,&lt;/em&gt; is a general-purpose execution engine that can be used for a variety of purposes, including networking, observability, and security. What we'll be discussing in this article was initially called &lt;em&gt;extended BPF&lt;/em&gt; (eBPF) to differentiate from the classic BPF, but now this technology is &lt;a href="https://www.brendangregg.com/systems-performance-2nd-edition-book.html"&gt;often referred to as just BPF&lt;/a&gt;, and that's what we'll call it here.&lt;/p&gt; &lt;p&gt;Having full visibility throughout the systems we build is a well established best practice. Usually, one knows which metrics to collect, and how and what to profile or instrument to understand why the system exhibits certain levels of performance. But all of this becomes more challenging as soon as the BPF layer is included. Despite years of development, it is still a black box in many ways.&lt;/p&gt; &lt;p&gt;But do not despair: this article will show, with some amount of creativity, that one can reveal what is going on under the hood. The article will begin with a userspace service that uses BPF programs attached to various syscalls to inspect system activity. It does the job, but what we really want is to understand the overhead of the BPF programs themselves. How do you look inside? That's the problem that we will ultimately tackle.&lt;/p&gt; &lt;h2&gt;Anatomy of a system call&lt;/h2&gt; &lt;p&gt;There is a tradition of capturing explanations of system calls (syscalls) under the title "&lt;a href="http://lwn.net/Articles/604287/"&gt;anatomy of a system call&lt;/a&gt;," which we diligently follow. Since we acquire most of the information from syscalls, the first step is understanding how they work.&lt;/p&gt; &lt;p&gt;Each architecture application binary interface (ABI) has requirements influencing how system calls work. Let’s limit our discussion to x86_64. The standard ABI for how x86_64 is to put the system call number into the &lt;code&gt;RAX&lt;/code&gt; register and the other parameters into specific registers, then issue the &lt;a href="https://www.intel.com/content/www/us/en/architecture-and-technology/64-ia-32-architectures-software-developer-vol-2b-manual.html"&gt;SYSCALL&lt;/a&gt; instruction, goes something like this:&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;code&gt;SYSCALL&lt;/code&gt; invokes an OS system call handler at privilege level 0. It does so by loading RIP from the IA32_LSTAR MSR after saving the address of the instruction following syscall into RCX. The &lt;code&gt;WRMSR&lt;/code&gt; instruction ensures that the IA32_LSTAR MSR always contains a canonical address.&lt;/p&gt; &lt;p&gt;At system startup, the kernel provides a custom &lt;code&gt;entry_SYSCALL_64&lt;/code&gt; function for handling syscalls and writes the address of this handler function to the &lt;code&gt;MSR_LSTAR&lt;/code&gt; register. The final step is to call the function pointer from the system call table using the number stored in &lt;code&gt;RAX&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Now, there could be a set of hooks specified, to be invoked before the execution of the actual syscall. It could be a custom probe registered for the corresponding static tracepoint or dynamic kprobe. We need to use them to instrument our application. Here is where things get tricky.&lt;/p&gt; &lt;h2&gt;Who traces the tracer?&lt;/h2&gt; &lt;p&gt;The main problem with measuring performance is measuring the right thing. In the case of measuring the performance of a program responsible for tracing another, this can be quite challenging. Consider &lt;code&gt;sys_enter&lt;/code&gt; and &lt;code&gt;sys_exit&lt;/code&gt; tracepoints that fire before or after a syscall is executed. We have BPF programs performing some activity when triggering those tracepoints. The exercise is to measure time spent in those programs.&lt;/p&gt; &lt;p&gt;There is some machinery in the kernel itself to collect statistics about BPF program runtime that give us cumulative time and number of runs for a particular program:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; $ sysctl -w kernel.bpf_stats_enabled=1 $ bpftool prog [...] 379: raw_tracepoint [...] run_time_ns 35875602162 run_cnt 160512637 &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Such aggregated numbers are good for sanity checks; but usually, they are not enough.&lt;/p&gt; &lt;p&gt;Another naive approach is to follow the same strategy as instrumenting normal userspace applications. Trace the same points, looking at any difference in performance (i.e., overall syscall latency) between the tracing program running and not running. All things considered, this approach could work, but only if you can guarantee that the performance-measuring probe is executed at the right time: before the start of the tracing program, and after it finishes (see Figure 1).&lt;/p&gt; &lt;figure role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/syscall_tracing_1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/syscall_tracing_1.png?itok=JPSDGPWF" width="243" height="400" alt="Two BPF programs are attached to the sys_enter/sys_exit tracing points of the syscall" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: Two BPF programs are attached to the sys_enter/sys_exit tracing points of the syscall. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;But alas, this will never happen because BPF programs are designed to be independent. So it barely makes sense to talk about their ordering.&lt;/p&gt; &lt;p&gt;Given the difficulty of getting the execution timing right, can we measure from a different point? Our first thought was to measure inside the probes themselves instead. That way, we could ignore all the cruft of the kernel running the syscall and focus on our execution. If we can measure that correctly, then that should give us the overhead. Simple, right? In theory, yes. But in practice, it was a bit more complicated.&lt;/p&gt; &lt;p&gt;The main difficulty was getting the information out of the BPF probe or the kernel module. Initially, we tried a quick and dirty approach of writing a message to the trace pipe and then consuming and processing those events to get the data.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; //somewhere inside your BPF prog bpf_trace_printk("Start timestamp: %lld", ts); &lt;/code&gt; &lt;/pre&gt; &lt;pre&gt; &lt;code&gt; $ cat /sys/kernel/debug/tracing/trace_pipe $ bpftool prog tracelog &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;This gave us promising initial results. However, it was not practical because it introduced significant measurement overhead.&lt;/p&gt; &lt;p&gt;Another point to measure could be a kernel function on the way to the syscall. We wondered whether there was kernel code around the syscall that we can attach to instead, guaranteeing the desirable probe execution order. By examining stacktraces captured via ftrace, we found that there is a small function that does just that. On amd64, it is called &lt;code&gt;do_syscall_64&lt;/code&gt;. It is slightly higher in the call stack than &lt;code&gt;sys_enter&lt;/code&gt; and &lt;code&gt;sys_exit&lt;/code&gt;, so we can measure latency from the start of &lt;code&gt;do_syscall_64&lt;/code&gt; to the end of the function, which will include any overhead from our probes. Is this ideal, or not?&lt;/p&gt; &lt;h2&gt;Tale of two probes&lt;/h2&gt; &lt;p&gt;One minor inconvenience with &lt;code&gt;do_syscall_64&lt;/code&gt; is that on kernels newer than 5.6, it can’t be used for this measurement because of a notrace marking. In this sense, we end up at the mercy of kernel internals. But there are more annoying problems along the way.&lt;/p&gt; &lt;p&gt;When we first fired up the measurements using kprobe and kretprobe to attach to the start/finish, we noticed that while the kprobe fired consistently, there was only a small number of kretprobe executions. Obviously, this didn’t make any sense because the calls were definitely complete, and there was no problem in userspace indicating that the syscalls were running correctly. Luckily, the &lt;a href="https://docs.kernel.org/trace/kprobes.html#how-does-a-return-probe-work"&gt;kernel documentation&lt;/a&gt; provided some answers.&lt;/p&gt; &lt;p&gt;A kprobe implements a kretprobe on the function entry. That probe stores the return address of the function and overwrites it with a trampoline address. When the function returns, the trampoline calls into the user-provided probe (i.e., our performance measuring BPF program). So why don’t we see all the returns?&lt;/p&gt; &lt;p&gt;While the probed function is executing, an object of type &lt;code&gt;kretprobe_instance&lt;/code&gt; stores its return address. Before calling &lt;code&gt;register_kretprobe()&lt;/code&gt;, the user sets the &lt;code&gt;maxactive&lt;/code&gt; field of the kretprobe struct to specify how many instances of simultaneous probing for the specified function can be probed simultaneously. &lt;code&gt;register_kretprobe()&lt;/code&gt; pre-allocates the indicated number of kretprobe_instance objects.&lt;/p&gt; &lt;p&gt;The problem is that there is a limit to the number of simultaneously stored return addresses. If you're running on a very busy codepath (like on every system call), then you're going to fill up this list very quickly and inevitably drop many events. The first experiments utilized &lt;code&gt;bpftrace&lt;/code&gt;, which uses the perf API and does not support specifying &lt;code&gt;maxactive&lt;/code&gt;. However, configuration is possible in a custom bcc script. In our case, we had to set it to a large value to capture all the events that occurred.&lt;/p&gt; &lt;p&gt;If you are curious, there is an alternative approach. The functions &lt;code&gt;kfunc&lt;/code&gt; and &lt;code&gt;kretfunc&lt;/code&gt; in &lt;code&gt;bpftrace&lt;/code&gt; use the fentry/fexit mechanism and BPF trampolines to do the same process, and they are not affected by kprobe machinery with &lt;code&gt;maxactive&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;When you find a good solution, look for a better one&lt;/h2&gt; &lt;p&gt;This solution is good, but not perfect. It is a reasonable way to collect the measurements. It covers not only BPF programs but also the underlying syscall. This brings a lot of variance and annoying noise into the captured data. Is there a way to make the measurements narrower?&lt;/p&gt; &lt;p&gt;The answer: BPF Type Format (BTF).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/counter-small_1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/counter-small_1.png?itok=1w58ZEG-" width="600" height="248" alt="Number of abbreviations is going down" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Shows the number of abbreviations going down. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: With the introduction of BTF, there is one fewer three-letter abbreviation available.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;When BTF information is available for the BPF program, the kernel JIT compiler emits instructions for providing fentry/fexit (seems like jumps &lt;code&gt;0xE9&lt;/code&gt; ). We could use those to attach two more monitoring BPF programs to the start/finish of our target BPF program and collect various events in between. In this way, one measures only a particular BPF program without including anything else. In fact, &lt;code&gt;bpftool prog profile&lt;/code&gt; and new &lt;code&gt;perf stat -b&lt;/code&gt; work in the same way.&lt;/p&gt; &lt;h2&gt;Profiling BPF programs&lt;/h2&gt; &lt;p&gt;So far, this discussion has revolved around getting counters between two points. But we can profile our BPF programs to understand what is happening at the instruction level.&lt;/p&gt; &lt;p&gt;We can profile a BPF program as part of any other kernel activity, but there seems to be no way to profile only one program. However, there is one possible approach to acquiring the tag of the BPF program: record samples of kernel activity, then annotate only those parts.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; $ bpftool prog id 5 5: tracepoint name &lt;tp_name&gt; tag 19c24c00f06f9dce gpl $ perf record ... $ perf annotate -l -P bpf_prog19c24c00f06f9dce [...] // bpf_prog_19c24c00f06f9dce[48] 13.56 : 48:callq 0xffffffffc5dfe8cc 0.00 : 4d:mov -0x8(%rbp),%edi 0.00 : 50:and $0x2,%rdi 0.00 : 54:test %rdi,%rdi [...] &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;The resulting annotated instructions match exactly to the JITed dump of the BPF program from bpftool.&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;Hopefully, the information described here helps to shed some light on the darkest corners of your system. There is still much more to learn and develop, but a journey of a thousand miles begins with a first step.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/22/measuring-bpf-performance-tips-tricks-and-best-practices" title="Measuring BPF performance: Tips, tricks, and best practices"&gt;Measuring BPF performance: Tips, tricks, and best practices&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Dmitrii Dolgov, Giles Hutton</dc:creator><dc:date>2022-06-22T07:00:00Z</dc:date></entry></feed>
